fastapi>=0.104.1
uvicorn[standard]>=0.24.0
python-multipart>=0.0.6
aiofiles>=23.2.1
sqlalchemy>=2.0.23
pydantic>=2.5.0
python-dotenv>=1.0.0
aiosqlite>=0.17.0
opencv-python>=4.8.1.78
numpy>=1.25.2
pillow>=10.1.0
pdf2image>=1.16.3
pytesseract>=0.3.10
easyocr>=1.7.0
requests>=2.31.0
pytest>=7.4.3
pytest-asyncio>=0.21.1
pytest-cov>=4.1.0
celery>=5.3.4
redis>=5.0.1

# LLM Backend - Google Gemini (free tier available)
google-generativeai>=0.3.2

# Optional LLM backends (commented out)
# Option 1: OpenAI (paid, but high quality)
# openai>=1.3.5

# Option 3: Hugging Face local models (completely free)
# transformers>=4.36.0
# torch>=2.1.0
# accelerate>=0.25.0

# Option 4: Ollama (completely free, local)
# requests>=2.31.0  # Already included above
easyocr>=1.7.0
requests>=2.31.0
pytest>=7.4.3
pytest-asyncio>=0.21.1
pytest-cov>=4.1.0
celery>=5.3.4
redis>=5.0.1

# LLM BACKENDS - Choose based on your needs

# Option 1: OpenAI (paid, but high quality)
# openai>=1.3.5

# Option 2: Google Gemini (free tier available)
google-generativeai>=0.3.2

# Option 3: Hugging Face local models (completely free)
# transformers>=4.36.0
# torch>=2.1.0
# accelerate>=0.25.0

# Option 4: Ollama (completely free, local)
# No pip package needed - install Ollama separately from: https://ollama.ai/
